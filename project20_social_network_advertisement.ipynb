{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15728773</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>58000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15598044</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>84000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15694829</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15600575</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15727311</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>65000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15570769</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15606274</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>52000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15746139</td>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>86000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15704987</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>18000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15628972</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>82000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15697686</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15733883</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>25000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15617482</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>26000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15704583</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>28000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15621083</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>29000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15649487</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>22000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15736760</td>\n",
       "      <td>Female</td>\n",
       "      <td>47</td>\n",
       "      <td>49000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15714658</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15599081</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>22000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15705113</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15631159</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15792818</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>28000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15633531</td>\n",
       "      <td>Female</td>\n",
       "      <td>47</td>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15744529</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15669656</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>18000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>15611430</td>\n",
       "      <td>Female</td>\n",
       "      <td>60</td>\n",
       "      <td>46000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>15774744</td>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "      <td>83000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>15629885</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>73000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>15708791</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>130000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>15793890</td>\n",
       "      <td>Female</td>\n",
       "      <td>37</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>15646091</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>32000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>15596984</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>74000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>15800215</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>53000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>15577806</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>15749381</td>\n",
       "      <td>Female</td>\n",
       "      <td>58</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>15683758</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>64000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>15670615</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>33000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>15715622</td>\n",
       "      <td>Female</td>\n",
       "      <td>44</td>\n",
       "      <td>139000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>15707634</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>28000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>15806901</td>\n",
       "      <td>Female</td>\n",
       "      <td>57</td>\n",
       "      <td>33000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>15775335</td>\n",
       "      <td>Male</td>\n",
       "      <td>56</td>\n",
       "      <td>60000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>15724150</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>39000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>15627220</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>71000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>15672330</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>34000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>15668521</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>15807837</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>33000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>15592570</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>15748589</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>45000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>15635893</td>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "      <td>42000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>15757632</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>59000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0    15624510    Male   19            19000          0\n",
       "1    15810944    Male   35            20000          0\n",
       "2    15668575  Female   26            43000          0\n",
       "3    15603246  Female   27            57000          0\n",
       "4    15804002    Male   19            76000          0\n",
       "5    15728773    Male   27            58000          0\n",
       "6    15598044  Female   27            84000          0\n",
       "7    15694829  Female   32           150000          1\n",
       "8    15600575    Male   25            33000          0\n",
       "9    15727311  Female   35            65000          0\n",
       "10   15570769  Female   26            80000          0\n",
       "11   15606274  Female   26            52000          0\n",
       "12   15746139    Male   20            86000          0\n",
       "13   15704987    Male   32            18000          0\n",
       "14   15628972    Male   18            82000          0\n",
       "15   15697686    Male   29            80000          0\n",
       "16   15733883    Male   47            25000          1\n",
       "17   15617482    Male   45            26000          1\n",
       "18   15704583    Male   46            28000          1\n",
       "19   15621083  Female   48            29000          1\n",
       "20   15649487    Male   45            22000          1\n",
       "21   15736760  Female   47            49000          1\n",
       "22   15714658    Male   48            41000          1\n",
       "23   15599081  Female   45            22000          1\n",
       "24   15705113    Male   46            23000          1\n",
       "25   15631159    Male   47            20000          1\n",
       "26   15792818    Male   49            28000          1\n",
       "27   15633531  Female   47            30000          1\n",
       "28   15744529    Male   29            43000          0\n",
       "29   15669656    Male   31            18000          0\n",
       "..        ...     ...  ...              ...        ...\n",
       "370  15611430  Female   60            46000          1\n",
       "371  15774744    Male   60            83000          1\n",
       "372  15629885  Female   39            73000          0\n",
       "373  15708791    Male   59           130000          1\n",
       "374  15793890  Female   37            80000          0\n",
       "375  15646091  Female   46            32000          1\n",
       "376  15596984  Female   46            74000          0\n",
       "377  15800215  Female   42            53000          0\n",
       "378  15577806    Male   41            87000          1\n",
       "379  15749381  Female   58            23000          1\n",
       "380  15683758    Male   42            64000          0\n",
       "381  15670615    Male   48            33000          1\n",
       "382  15715622  Female   44           139000          1\n",
       "383  15707634    Male   49            28000          1\n",
       "384  15806901  Female   57            33000          1\n",
       "385  15775335    Male   56            60000          1\n",
       "386  15724150  Female   49            39000          1\n",
       "387  15627220    Male   39            71000          0\n",
       "388  15672330    Male   47            34000          1\n",
       "389  15668521  Female   48            35000          1\n",
       "390  15807837    Male   48            33000          1\n",
       "391  15592570    Male   47            23000          1\n",
       "392  15748589  Female   45            45000          1\n",
       "393  15635893    Male   60            42000          1\n",
       "394  15757632  Female   39            59000          0\n",
       "395  15691863  Female   46            41000          1\n",
       "396  15706071    Male   51            23000          1\n",
       "397  15654296  Female   50            20000          1\n",
       "398  15755018    Male   36            33000          0\n",
       "399  15594041  Female   49            36000          1\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_social=pd.read_csv(\"social_networking.txt\",sep=\",\")\n",
    "df_social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID            0\n",
       "Gender             0\n",
       "Age                0\n",
       "EstimatedSalary    0\n",
       "Purchased          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets chcek the presence of null values in the dataset\n",
    "df_social.isnull().sum()\n",
    "#There  are no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID             int64\n",
       "Gender             object\n",
       "Age                 int64\n",
       "EstimatedSalary     int64\n",
       "Purchased           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check the datatypes of the columns\n",
    "df_social.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we know that User ID wont affect the purchasing pattern so we can drop\n",
    "df_social.drop(columns=[\"User ID\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets chcek the count of each type of target class\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.countplot(x=\"Purchased\",data=df_social)\n",
    "plt.show()\n",
    "# it is the imbalanced set with difference around 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets chcek count of purchase with respect to gender\n",
    "sns.countplot(x=\"Purchased\",hue=\"Gender\",data=df_social.loc[df_social[\"Purchased\"]==1])\n",
    "plt.show()\n",
    "#Count of females sho purchased is more than men wh did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets check in which age group shopping was more\n",
    "plt.hist(x=\"Age\",data=df_social.loc[df_social[\"Purchased\"]==1])\n",
    "plt.show()\n",
    "#So maximum purchase was done by age group 45 to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#What is the average salary of people who purchased and who didn't\n",
    "sns.barplot(x=\"Purchased\",y=\"EstimatedSalary\",data=df_social)\n",
    "plt.show()\n",
    "#People who did purchasing have average salary more than who didn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets chcek in which salary group purchasng was highest\n",
    "plt.hist(x=\"EstimatedSalary\",data=df_social.loc[df_social[\"Purchased\"]==1])\n",
    "plt.show()\n",
    "#people with salary least and highest did maximum purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                0.231337\n",
       "EstimatedSalary    0.495024\n",
       "Purchased          0.596903\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets chcek the skewness of the dataset\n",
    "df_social.skew()\n",
    "#from below output skewness seems fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets seprate the input and output from dataset\n",
    "df_x=df_social.drop(columns=[\"Purchased\"])\n",
    "y=df_social[[\"Purchased\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets use pd.get_dummies to convert input dataset columns into integers\n",
    "df_x=pd.get_dummies(df_x,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "F:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#let's bring the features to same scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(df_x)\n",
    "x=sc.transform(df_x)\n",
    "x=pd.DataFrame(x,columns=df_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since it is imbalanced dataset so we will focus on auc-roc score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "def max_aucroc_score(clf,df_x,y):\n",
    "    max_aucroc_score=0\n",
    "    for r_state in range(42,100):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(df_x, y,random_state = r_state,test_size=0.10,stratify=y)\n",
    "        x_train, y_train = SMOTE().fit_sample(x_train, y_train)\n",
    "        clf.fit(x_train,y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        aucroc_scr=roc_auc_score(y_test,y_pred)\n",
    "        print(\"auc roc score corresponding to \",r_state,\" is \",aucroc_scr)\n",
    "        if aucroc_scr>max_aucroc_score:\n",
    "            max_aucroc_score=aucroc_scr\n",
    "            final_r_state=r_state\n",
    "    print(\"max auc roc score corresponding to \",final_r_state,\" is \",max_aucroc_score)\n",
    "    return final_r_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets make a function which evaluates the model using cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def model_evaluation(model,x,y):\n",
    "    print(\"Mean roc auc score for classifier: \",cross_val_score(model,x,y,cv=10,scoring=\"roc_auc\").mean())\n",
    "    print(\"standard deviation in roc auc score for classifier: \",cross_val_score(model,x,y,cv=10,scoring=\"roc_auc\").std())\n",
    "    print(cross_val_score(model,x,y,cv=10,scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc roc score corresponding to  42  is  0.8901098901098902\n",
      "auc roc score corresponding to  43  is  0.8708791208791209\n",
      "auc roc score corresponding to  44  is  0.8159340659340659\n",
      "auc roc score corresponding to  45  is  0.9642857142857143\n",
      "auc roc score corresponding to  46  is  0.9258241758241759\n",
      "auc roc score corresponding to  47  is  0.9065934065934066\n",
      "auc roc score corresponding to  48  is  0.8131868131868132\n",
      "auc roc score corresponding to  49  is  0.9038461538461539\n",
      "auc roc score corresponding to  50  is  0.7967032967032968\n",
      "auc roc score corresponding to  51  is  0.8324175824175825\n",
      "auc roc score corresponding to  52  is  0.8543956043956044\n",
      "auc roc score corresponding to  53  is  0.7445054945054945\n",
      "auc roc score corresponding to  54  is  0.835164835164835\n",
      "auc roc score corresponding to  55  is  0.9615384615384616\n",
      "auc roc score corresponding to  56  is  0.8873626373626373\n",
      "auc roc score corresponding to  57  is  0.8131868131868132\n",
      "auc roc score corresponding to  58  is  0.8159340659340659\n",
      "auc roc score corresponding to  59  is  0.8708791208791209\n",
      "auc roc score corresponding to  60  is  0.9093406593406594\n",
      "auc roc score corresponding to  61  is  0.8846153846153846\n",
      "auc roc score corresponding to  62  is  0.8736263736263735\n",
      "auc roc score corresponding to  63  is  0.9093406593406594\n",
      "auc roc score corresponding to  64  is  0.8186813186813188\n",
      "auc roc score corresponding to  65  is  0.8708791208791209\n",
      "auc roc score corresponding to  66  is  0.8131868131868132\n",
      "auc roc score corresponding to  67  is  0.8681318681318682\n",
      "auc roc score corresponding to  68  is  0.8516483516483516\n",
      "auc roc score corresponding to  69  is  0.9230769230769231\n",
      "auc roc score corresponding to  70  is  0.835164835164835\n",
      "auc roc score corresponding to  71  is  0.8901098901098902\n",
      "auc roc score corresponding to  72  is  0.8214285714285714\n",
      "auc roc score corresponding to  73  is  0.8131868131868132\n",
      "auc roc score corresponding to  74  is  0.7774725274725274\n",
      "auc roc score corresponding to  75  is  0.8159340659340659\n",
      "auc roc score corresponding to  76  is  0.7087912087912087\n",
      "auc roc score corresponding to  77  is  0.7967032967032968\n",
      "auc roc score corresponding to  78  is  0.8708791208791209\n",
      "auc roc score corresponding to  79  is  0.7774725274725274\n",
      "auc roc score corresponding to  80  is  0.8324175824175825\n",
      "auc roc score corresponding to  81  is  0.7417582417582418\n",
      "auc roc score corresponding to  82  is  0.9423076923076923\n",
      "auc roc score corresponding to  83  is  0.8708791208791209\n",
      "auc roc score corresponding to  84  is  0.7197802197802197\n",
      "auc roc score corresponding to  85  is  0.8708791208791209\n",
      "auc roc score corresponding to  86  is  0.8681318681318682\n",
      "auc roc score corresponding to  87  is  0.7802197802197803\n",
      "auc roc score corresponding to  88  is  0.8543956043956044\n",
      "auc roc score corresponding to  89  is  0.7967032967032968\n",
      "auc roc score corresponding to  90  is  0.8708791208791209\n",
      "auc roc score corresponding to  91  is  0.8489010989010988\n",
      "auc roc score corresponding to  92  is  0.9450549450549451\n",
      "auc roc score corresponding to  93  is  0.9258241758241759\n",
      "auc roc score corresponding to  94  is  0.8131868131868132\n",
      "auc roc score corresponding to  95  is  0.7307692307692307\n",
      "auc roc score corresponding to  96  is  0.8901098901098902\n",
      "auc roc score corresponding to  97  is  0.835164835164835\n",
      "auc roc score corresponding to  98  is  0.7390109890109889\n",
      "auc roc score corresponding to  99  is  0.8461538461538461\n",
      "max auc roc score corresponding to  45  is  0.9642857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets chcek logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "lg_clf=LogisticRegression()\n",
    "max_aucroc_score(lg_clf,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC CLASSIFIER\n",
      "\n",
      "\n",
      "Mean roc auc score for classifier:  0.9396080586080586\n",
      "standard deviation in roc auc score for classifier:  0.05465643622432407\n",
      "[1.         0.91666667 0.9974359  0.97802198 0.99175824 0.98351648\n",
      " 0.92582418 0.88571429 0.85714286 0.86      ]\n"
     ]
    }
   ],
   "source": [
    "#lets print the scores for logistic regression\n",
    "print(\"LOGISTIC CLASSIFIER\\n\\n\")\n",
    "model_evaluation(lg_clf,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'kernel': 'poly'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets chcek SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svc=SVC()\n",
    "parameters={\"kernel\":[\"linear\", \"poly\", \"rbf\"],\"C\":[0.001,0.01,0.1,1,10]}\n",
    "clf = GridSearchCV(svc, parameters, cv=10,scoring=\"roc_auc\")\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc roc score corresponding to  42  is  0.8571428571428572\n",
      "auc roc score corresponding to  43  is  0.9258241758241759\n",
      "auc roc score corresponding to  44  is  0.9450549450549451\n",
      "auc roc score corresponding to  45  is  0.9642857142857143\n",
      "auc roc score corresponding to  46  is  0.9093406593406594\n",
      "auc roc score corresponding to  47  is  0.8708791208791209\n",
      "auc roc score corresponding to  48  is  0.9258241758241759\n",
      "auc roc score corresponding to  49  is  0.8516483516483516\n",
      "auc roc score corresponding to  50  is  0.8543956043956044\n",
      "auc roc score corresponding to  51  is  0.8708791208791209\n",
      "auc roc score corresponding to  52  is  0.8928571428571428\n",
      "auc roc score corresponding to  53  is  0.7637362637362637\n",
      "auc roc score corresponding to  54  is  0.8736263736263735\n",
      "auc roc score corresponding to  55  is  0.9285714285714286\n",
      "auc roc score corresponding to  56  is  0.8901098901098902\n",
      "auc roc score corresponding to  57  is  0.8708791208791209\n",
      "auc roc score corresponding to  58  is  0.8186813186813188\n",
      "auc roc score corresponding to  59  is  0.9093406593406594\n",
      "auc roc score corresponding to  60  is  0.9093406593406594\n",
      "auc roc score corresponding to  61  is  0.8681318681318682\n",
      "auc roc score corresponding to  62  is  0.8928571428571428\n",
      "auc roc score corresponding to  63  is  0.8571428571428572\n",
      "auc roc score corresponding to  64  is  0.7115384615384616\n",
      "auc roc score corresponding to  65  is  0.8543956043956044\n",
      "auc roc score corresponding to  66  is  0.7994505494505495\n",
      "auc roc score corresponding to  67  is  0.9093406593406594\n",
      "auc roc score corresponding to  68  is  0.8901098901098902\n",
      "auc roc score corresponding to  69  is  0.8901098901098902\n",
      "auc roc score corresponding to  70  is  0.8021978021978021\n",
      "auc roc score corresponding to  71  is  0.9285714285714286\n",
      "auc roc score corresponding to  72  is  0.7857142857142857\n",
      "auc roc score corresponding to  73  is  0.8901098901098902\n",
      "auc roc score corresponding to  74  is  0.9423076923076923\n",
      "auc roc score corresponding to  75  is  0.8543956043956044\n",
      "auc roc score corresponding to  76  is  0.8021978021978021\n",
      "auc roc score corresponding to  77  is  0.835164835164835\n",
      "auc roc score corresponding to  78  is  0.8928571428571428\n",
      "auc roc score corresponding to  79  is  0.835164835164835\n",
      "auc roc score corresponding to  80  is  0.8873626373626373\n",
      "auc roc score corresponding to  81  is  0.7637362637362637\n",
      "auc roc score corresponding to  82  is  0.9093406593406594\n",
      "auc roc score corresponding to  83  is  0.9093406593406594\n",
      "auc roc score corresponding to  84  is  0.8901098901098902\n",
      "auc roc score corresponding to  85  is  0.8543956043956044\n",
      "auc roc score corresponding to  86  is  0.8901098901098902\n",
      "auc roc score corresponding to  87  is  0.8543956043956044\n",
      "auc roc score corresponding to  88  is  0.8214285714285714\n",
      "auc roc score corresponding to  89  is  0.8543956043956044\n",
      "auc roc score corresponding to  90  is  0.8736263736263735\n",
      "auc roc score corresponding to  91  is  0.8708791208791209\n",
      "auc roc score corresponding to  92  is  0.8928571428571428\n",
      "auc roc score corresponding to  93  is  0.8543956043956044\n",
      "auc roc score corresponding to  94  is  0.8159340659340659\n",
      "auc roc score corresponding to  95  is  0.75\n",
      "auc roc score corresponding to  96  is  0.8186813186813188\n",
      "auc roc score corresponding to  97  is  0.8736263736263735\n",
      "auc roc score corresponding to  98  is  0.7994505494505495\n",
      "auc roc score corresponding to  99  is  0.8873626373626373\n",
      "max auc roc score corresponding to  45  is  0.9642857142857143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc=SVC(C=0.1,kernel=\"poly\")\n",
    "max_aucroc_score(svc,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM CLASSIFIER\n",
      "\n",
      "\n",
      "Mean roc auc score for classifier:  0.9504102564102566\n",
      "standard deviation in roc auc score for classifier:  0.04528440274963797\n",
      "[0.99230769 0.90384615 0.99487179 0.99175824 0.99175824 0.98351648\n",
      " 0.92032967 0.91142857 0.86285714 0.95142857]\n"
     ]
    }
   ],
   "source": [
    "#lets print the scores for logistic regression\n",
    "print(\"SVM CLASSIFIER\\n\\n\")\n",
    "model_evaluation(svc,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 26}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets chcek KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "kc=KNeighborsClassifier()\n",
    "neighbors={\"n_neighbors\":range(1,30)}\n",
    "clf = GridSearchCV(kc, neighbors, cv=10,scoring=\"roc_auc\")\n",
    "clf.fit(x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc roc score corresponding to  42  is  0.9093406593406594\n",
      "auc roc score corresponding to  43  is  0.9807692307692308\n",
      "auc roc score corresponding to  44  is  0.9615384615384616\n",
      "auc roc score corresponding to  45  is  0.9450549450549451\n",
      "auc roc score corresponding to  46  is  0.9807692307692308\n",
      "auc roc score corresponding to  47  is  0.9065934065934066\n",
      "auc roc score corresponding to  48  is  0.9450549450549451\n",
      "auc roc score corresponding to  49  is  0.8708791208791209\n",
      "auc roc score corresponding to  50  is  0.9450549450549451\n",
      "auc roc score corresponding to  51  is  0.8516483516483516\n",
      "auc roc score corresponding to  52  is  0.9642857142857143\n",
      "auc roc score corresponding to  53  is  0.8901098901098902\n",
      "auc roc score corresponding to  54  is  0.9093406593406594\n",
      "auc roc score corresponding to  55  is  0.8708791208791209\n",
      "auc roc score corresponding to  56  is  0.9450549450549451\n",
      "auc roc score corresponding to  57  is  0.9615384615384616\n",
      "auc roc score corresponding to  58  is  0.9450549450549451\n",
      "auc roc score corresponding to  59  is  0.9065934065934066\n",
      "auc roc score corresponding to  60  is  0.9258241758241759\n",
      "auc roc score corresponding to  61  is  0.9230769230769231\n",
      "auc roc score corresponding to  62  is  0.9450549450549451\n",
      "auc roc score corresponding to  63  is  0.9093406593406594\n",
      "auc roc score corresponding to  64  is  0.835164835164835\n",
      "auc roc score corresponding to  65  is  0.9093406593406594\n",
      "auc roc score corresponding to  66  is  0.9258241758241759\n",
      "auc roc score corresponding to  67  is  0.9450549450549451\n",
      "auc roc score corresponding to  68  is  0.9065934065934066\n",
      "auc roc score corresponding to  69  is  0.9615384615384616\n",
      "auc roc score corresponding to  70  is  0.8736263736263735\n",
      "auc roc score corresponding to  71  is  0.9285714285714286\n",
      "auc roc score corresponding to  72  is  0.8736263736263735\n",
      "auc roc score corresponding to  73  is  0.9258241758241759\n",
      "auc roc score corresponding to  74  is  0.9807692307692308\n",
      "auc roc score corresponding to  75  is  0.9423076923076923\n",
      "auc roc score corresponding to  76  is  0.8379120879120879\n",
      "auc roc score corresponding to  77  is  0.8873626373626373\n",
      "auc roc score corresponding to  78  is  0.9642857142857143\n",
      "auc roc score corresponding to  79  is  0.8708791208791209\n",
      "auc roc score corresponding to  80  is  0.9258241758241759\n",
      "auc roc score corresponding to  81  is  0.835164835164835\n",
      "auc roc score corresponding to  82  is  0.9642857142857143\n",
      "auc roc score corresponding to  83  is  0.9807692307692308\n",
      "auc roc score corresponding to  84  is  0.9065934065934066\n",
      "auc roc score corresponding to  85  is  0.9615384615384616\n",
      "auc roc score corresponding to  86  is  0.9065934065934066\n",
      "auc roc score corresponding to  87  is  0.8928571428571428\n",
      "auc roc score corresponding to  88  is  0.8928571428571428\n",
      "auc roc score corresponding to  89  is  0.9615384615384616\n",
      "auc roc score corresponding to  90  is  0.9258241758241759\n",
      "auc roc score corresponding to  91  is  0.9065934065934066\n",
      "auc roc score corresponding to  92  is  0.9615384615384616\n",
      "auc roc score corresponding to  93  is  0.835164835164835\n",
      "auc roc score corresponding to  94  is  0.8186813186813188\n",
      "auc roc score corresponding to  95  is  0.9285714285714286\n",
      "auc roc score corresponding to  96  is  0.9258241758241759\n",
      "auc roc score corresponding to  97  is  0.9230769230769231\n",
      "auc roc score corresponding to  98  is  0.9065934065934066\n",
      "auc roc score corresponding to  99  is  0.9230769230769231\n",
      "max auc roc score corresponding to  43  is  0.9807692307692308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc=KNeighborsClassifier(n_neighbors=26)\n",
    "max_aucroc_score(kc,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLASSIFIER\n",
      "\n",
      "\n",
      "Mean roc auc score for classifier:  0.958175824175824\n",
      "standard deviation in roc auc score for classifier:  0.04042436491196704\n",
      "[1.         0.94358974 0.97948718 0.99725275 0.98489011 0.97115385\n",
      " 0.9010989  0.91285714 0.89142857 1.        ]\n"
     ]
    }
   ],
   "source": [
    "#lets print the scores for KKN classifier\n",
    "print(\"KNN CLASSIFIER\\n\\n\")\n",
    "model_evaluation(kc,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc roc score corresponding to  42  is  0.8543956043956044\n",
      "auc roc score corresponding to  43  is  0.8901098901098902\n",
      "auc roc score corresponding to  44  is  0.7967032967032968\n",
      "auc roc score corresponding to  45  is  0.8736263736263735\n",
      "auc roc score corresponding to  46  is  0.8708791208791209\n",
      "auc roc score corresponding to  47  is  0.9230769230769231\n",
      "auc roc score corresponding to  48  is  0.7609890109890111\n",
      "auc roc score corresponding to  49  is  0.8159340659340659\n",
      "auc roc score corresponding to  50  is  0.7994505494505495\n",
      "auc roc score corresponding to  51  is  0.8159340659340659\n",
      "auc roc score corresponding to  52  is  0.9258241758241759\n",
      "auc roc score corresponding to  53  is  0.7445054945054945\n",
      "auc roc score corresponding to  54  is  0.8186813186813188\n",
      "auc roc score corresponding to  55  is  0.7802197802197803\n",
      "auc roc score corresponding to  56  is  0.8736263736263735\n",
      "auc roc score corresponding to  57  is  0.8324175824175825\n",
      "auc roc score corresponding to  58  is  0.9450549450549451\n",
      "auc roc score corresponding to  59  is  0.7774725274725274\n",
      "auc roc score corresponding to  60  is  0.7472527472527473\n",
      "auc roc score corresponding to  61  is  0.8516483516483516\n",
      "auc roc score corresponding to  62  is  0.8214285714285714\n",
      "auc roc score corresponding to  63  is  0.7994505494505495\n",
      "auc roc score corresponding to  64  is  0.8708791208791209\n",
      "auc roc score corresponding to  65  is  0.7994505494505495\n",
      "auc roc score corresponding to  66  is  0.8131868131868132\n",
      "auc roc score corresponding to  67  is  0.9093406593406594\n",
      "auc roc score corresponding to  68  is  0.835164835164835\n",
      "auc roc score corresponding to  69  is  0.9258241758241759\n",
      "auc roc score corresponding to  70  is  0.8708791208791209\n",
      "auc roc score corresponding to  71  is  0.8186813186813188\n",
      "auc roc score corresponding to  72  is  0.8379120879120879\n",
      "auc roc score corresponding to  73  is  0.8873626373626373\n",
      "auc roc score corresponding to  74  is  0.8159340659340659\n",
      "auc roc score corresponding to  75  is  0.8708791208791209\n",
      "auc roc score corresponding to  76  is  0.7664835164835164\n",
      "auc roc score corresponding to  77  is  0.8516483516483516\n",
      "auc roc score corresponding to  78  is  0.8516483516483516\n",
      "auc roc score corresponding to  79  is  0.8846153846153846\n",
      "auc roc score corresponding to  80  is  0.8516483516483516\n",
      "auc roc score corresponding to  81  is  0.8708791208791209\n",
      "auc roc score corresponding to  82  is  0.8571428571428572\n",
      "auc roc score corresponding to  83  is  0.8736263736263735\n",
      "auc roc score corresponding to  84  is  0.7417582417582418\n",
      "auc roc score corresponding to  85  is  0.8186813186813188\n",
      "auc roc score corresponding to  86  is  0.8873626373626373\n",
      "auc roc score corresponding to  87  is  0.8708791208791209\n",
      "auc roc score corresponding to  88  is  0.7307692307692307\n",
      "auc roc score corresponding to  89  is  0.8708791208791209\n",
      "auc roc score corresponding to  90  is  0.8379120879120879\n",
      "auc roc score corresponding to  91  is  0.8159340659340659\n",
      "auc roc score corresponding to  92  is  0.9258241758241759\n",
      "auc roc score corresponding to  93  is  0.728021978021978\n",
      "auc roc score corresponding to  94  is  0.835164835164835\n",
      "auc roc score corresponding to  95  is  0.8186813186813188\n",
      "auc roc score corresponding to  96  is  0.835164835164835\n",
      "auc roc score corresponding to  97  is  0.8873626373626373\n",
      "auc roc score corresponding to  98  is  0.8159340659340659\n",
      "auc roc score corresponding to  99  is  0.793956043956044\n",
      "max auc roc score corresponding to  58  is  0.9450549450549451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets chcek the decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dc=DecisionTreeClassifier()\n",
    "max_aucroc_score(dc,df_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets chcek random forest also\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters={\"n_estimators\":[10,100,500]}\n",
    "rf_clf=RandomForestClassifier()\n",
    "clf = GridSearchCV(rf_clf, parameters, cv=10,scoring=\"roc_auc\")\n",
    "clf.fit(df_x,y)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc roc score corresponding to  42  is  0.8901098901098902\n",
      "auc roc score corresponding to  43  is  0.9258241758241759\n",
      "auc roc score corresponding to  44  is  0.9423076923076923\n",
      "auc roc score corresponding to  45  is  0.8928571428571428\n",
      "auc roc score corresponding to  46  is  0.8708791208791209\n",
      "auc roc score corresponding to  47  is  0.8873626373626373\n",
      "auc roc score corresponding to  48  is  0.9093406593406594\n",
      "auc roc score corresponding to  49  is  0.8516483516483516\n",
      "auc roc score corresponding to  50  is  0.8901098901098902\n",
      "auc roc score corresponding to  51  is  0.8324175824175825\n",
      "auc roc score corresponding to  52  is  0.9450549450549451\n",
      "auc roc score corresponding to  53  is  0.8159340659340659\n",
      "auc roc score corresponding to  54  is  0.8543956043956044\n",
      "auc roc score corresponding to  55  is  0.8901098901098902\n",
      "auc roc score corresponding to  56  is  0.9615384615384616\n",
      "auc roc score corresponding to  57  is  0.9423076923076923\n",
      "auc roc score corresponding to  58  is  0.9450549450549451\n",
      "auc roc score corresponding to  59  is  0.8708791208791209\n",
      "auc roc score corresponding to  60  is  0.8901098901098902\n",
      "auc roc score corresponding to  61  is  0.8873626373626373\n",
      "auc roc score corresponding to  62  is  0.8928571428571428\n",
      "auc roc score corresponding to  63  is  0.8379120879120879\n",
      "auc roc score corresponding to  64  is  0.8186813186813188\n",
      "auc roc score corresponding to  65  is  0.8708791208791209\n",
      "auc roc score corresponding to  66  is  0.9065934065934066\n",
      "auc roc score corresponding to  67  is  0.8901098901098902\n",
      "auc roc score corresponding to  68  is  0.8159340659340659\n",
      "auc roc score corresponding to  69  is  0.9615384615384616\n",
      "auc roc score corresponding to  70  is  0.9093406593406594\n",
      "auc roc score corresponding to  71  is  0.8928571428571428\n",
      "auc roc score corresponding to  72  is  0.8736263736263735\n",
      "auc roc score corresponding to  73  is  0.9065934065934066\n",
      "auc roc score corresponding to  74  is  0.9807692307692308\n",
      "auc roc score corresponding to  75  is  0.9065934065934066\n",
      "auc roc score corresponding to  76  is  0.8021978021978021\n",
      "auc roc score corresponding to  77  is  0.8873626373626373\n",
      "auc roc score corresponding to  78  is  0.8736263736263735\n",
      "auc roc score corresponding to  79  is  0.9230769230769231\n",
      "auc roc score corresponding to  80  is  0.8708791208791209\n",
      "auc roc score corresponding to  81  is  0.7637362637362637\n",
      "auc roc score corresponding to  82  is  0.9258241758241759\n",
      "auc roc score corresponding to  83  is  0.9450549450549451\n",
      "auc roc score corresponding to  84  is  0.8873626373626373\n",
      "auc roc score corresponding to  85  is  0.9615384615384616\n",
      "auc roc score corresponding to  86  is  0.9065934065934066\n",
      "auc roc score corresponding to  87  is  0.8736263736263735\n",
      "auc roc score corresponding to  88  is  0.8021978021978021\n",
      "auc roc score corresponding to  89  is  0.8324175824175825\n",
      "auc roc score corresponding to  90  is  0.8379120879120879\n",
      "auc roc score corresponding to  91  is  0.835164835164835\n",
      "auc roc score corresponding to  92  is  0.9258241758241759\n",
      "auc roc score corresponding to  93  is  0.7994505494505495\n",
      "auc roc score corresponding to  94  is  0.8708791208791209\n",
      "auc roc score corresponding to  95  is  0.9093406593406594\n",
      "auc roc score corresponding to  96  is  0.835164835164835\n",
      "auc roc score corresponding to  97  is  0.8516483516483516\n",
      "auc roc score corresponding to  98  is  0.8516483516483516\n",
      "auc roc score corresponding to  99  is  0.9038461538461539\n",
      "max auc roc score corresponding to  74  is  0.9807692307692308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_aucroc_score(rf_clf,df_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree CLASSIFIER\n",
      "\n",
      "\n",
      "Mean roc auc score for classifier:  0.8014798534798535\n",
      "standard deviation in roc auc score for classifier:  0.0554786611649116\n",
      "[0.81410256 0.69487179 0.84230769 0.87087912 0.82142857 0.83516484\n",
      " 0.72527473 0.84857143 0.73714286 0.86857143]\n"
     ]
    }
   ],
   "source": [
    "#Lets print the scores of decision tree\n",
    "print(\"Decision tree CLASSIFIER\\n\\n\")\n",
    "model_evaluation(dc,df_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CLASSIFIER\n",
      "\n",
      "\n",
      "Mean roc auc score for classifier:  0.9283516483516484\n",
      "standard deviation in roc auc score for classifier:  0.05245155670932689\n",
      "[0.9974359  0.89487179 0.91282051 0.99725275 0.99725275 0.81456044\n",
      " 0.88736264 0.92857143 0.86714286 0.99142857]\n"
     ]
    }
   ],
   "source": [
    "#Lets print the scores of random forest\n",
    "print(\"Random Forest CLASSIFIER\\n\\n\")\n",
    "model_evaluation(rf_clf,df_x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on above scores KNN is performing best\n",
    "#random state 43\n",
    "kc=KNeighborsClassifier(n_neighbors=26)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,random_state = 43,test_size=0.10,stratify=y)\n",
    "x_train, y_train = SMOTE().fit_sample(x_train, y_train)\n",
    "kc.fit(x_train,y_train)\n",
    "y_pred=kc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix \n",
      " [[25  1]\n",
      " [ 0 14]]\n",
      "f1 score is :  0.9655172413793104\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        26\n",
      "           1       0.93      1.00      0.97        14\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        40\n",
      "   macro avg       0.97      0.98      0.97        40\n",
      "weighted avg       0.98      0.97      0.98        40\n",
      "\n",
      "AUC ROC Score:  0.9807692307692308\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Confusion matrix \\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"f1 score is : \",f1_score(y_test,y_pred))\n",
    "print(\"classification report \\n\",classification_report(y_test,y_pred))\n",
    "print(\"AUC ROC Score: \",roc_auc_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
